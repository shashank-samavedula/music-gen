{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Music Generation using Deep Learning**\n",
        "\n",
        "This notebook demonstrates how to generate music using deep learning techniques, specifically an LSTM-based neural network. The process involves reading MIDI files, preprocessing the data, training the model, and using it to generate new music sequences."
      ],
      "metadata": {
        "id": "DTwnIPZetOfd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the required libraries\n",
        "from music21 import *\n",
        "import os\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import *\n",
        "from keras.models import *\n",
        "from keras.callbacks import *\n",
        "import keras.backend as K"
      ],
      "metadata": {
        "id": "FOFzVY4VvHY9"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Task 1: Read MIDI Files and Extract Notes**\n",
        "\n",
        "In this section, MIDI files are read and the individual notes are extracted from the piano instrument for further processing."
      ],
      "metadata": {
        "id": "arTIDw4_3lXt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#defining function to read MIDI files\n",
        "def read_midi(file):\n",
        "\n",
        "    print(\"Loading Music File:\",file)\n",
        "\n",
        "    notes=[]\n",
        "    notes_to_parse = None\n",
        "\n",
        "    #parsing a midi file\n",
        "    midi = converter.parse(file)\n",
        "\n",
        "    #grouping based on different instruments\n",
        "    s2 = instrument.partitionByInstrument(midi)\n",
        "\n",
        "    #Looping over all the instruments\n",
        "    for part in s2.parts:\n",
        "\n",
        "        #select elements of only piano\n",
        "        if 'Piano' in str(part):\n",
        "\n",
        "            notes_to_parse = part.recurse()\n",
        "\n",
        "            #finding whether a particular element is note or a chord\n",
        "            for element in notes_to_parse:\n",
        "\n",
        "                #note\n",
        "                if isinstance(element, note.Note):\n",
        "                    notes.append(str(element.pitch))\n",
        "\n",
        "                #chord\n",
        "                elif isinstance(element, chord.Chord):\n",
        "                    notes.append('.'.join(str(n) for n in element.normalOrder))\n",
        "\n",
        "    return np.array(notes)\n"
      ],
      "metadata": {
        "id": "W_NP4W0g7eAC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for listing down the file names\n",
        "import os\n",
        "\n",
        "#Array Processing\n",
        "import numpy as np\n",
        "\n",
        "#specify the path\n",
        "path='schubert/'\n",
        "\n",
        "#read all the filenames\n",
        "files=[i for i in os.listdir(path) if i.endswith(\".mid\")]\n",
        "\n",
        "#reading each midi file\n",
        "notes_array = np.array([read_midi(path+i) for i in files])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rnWQVbNtJFu",
        "outputId": "3d3d8c2d-fc9c-465a-ae86-8523bc4b6657"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Music File: schubert/beethoven_hammerklavier_2.mid\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/music21/midi/translate.py:863: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=5, channel=None, data=b'Copyright \\xa9 2008 by Bernd Krueger'>; getting generic Instrument\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Music File: schubert/beethoven_opus22_2.mid\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/music21/midi/translate.py:863: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=5, channel=None, data=b'Copyright \\xa9 2009 by Bernd Krueger'>; getting generic Instrument\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Music File: schubert/beethoven_opus10_3.mid\n",
            "Loading Music File: schubert/beethoven_hammerklavier_3.mid\n",
            "Loading Music File: schubert/beethoven_hammerklavier_4.mid\n",
            "Loading Music File: schubert/beethoven_hammerklavier_1.mid\n",
            "Loading Music File: schubert/beethoven_opus10_1.mid\n",
            "Loading Music File: schubert/beethoven_opus22_4.mid\n",
            "Loading Music File: schubert/beethoven_opus10_2.mid\n",
            "Loading Music File: schubert/beethoven_opus22_3.mid\n",
            "Loading Music File: schubert/beethoven_opus90_2.mid\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/music21/midi/translate.py:863: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=5, channel=None, data=b'Copyright \\xa9 2010 by Bernd Krueger'>; getting generic Instrument\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Music File: schubert/appass_2.mid\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/music21/midi/translate.py:863: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=5, channel=None, data=b'Copyright \\xa9 2001 by Bernd Kr\\xfcger'>; getting generic Instrument\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Music File: schubert/beethoven_les_adieux_3.mid\n",
            "Loading Music File: schubert/elise.mid\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/music21/midi/translate.py:863: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=0, channel=None, data=b'F\\xfcr Elise'>; getting generic Instrument\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/music21/midi/translate.py:863: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=3, channel=None, data=b'Beethoven F\\xfcr Elise'>; getting generic Instrument\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/music21/midi/translate.py:863: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=4, channel=None, data=b'Copyright \\xa9 2004 by Bernd Kr\\xfcger'>; getting generic Instrument\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Music File: schubert/beethoven_les_adieux_2.mid\n",
            "Loading Music File: schubert/waldstein_1.mid\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/music21/midi/translate.py:863: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=5, channel=None, data=b'Copyright \\xa9 2003 by Bernd Krueger'>; getting generic Instrument\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Music File: schubert/beethoven_opus22_1.mid\n",
            "Loading Music File: schubert/appass_1.mid\n",
            "Loading Music File: schubert/appass_3.mid\n",
            "Loading Music File: schubert/beethoven_les_adieux_1.mid\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-13269b8794bc>:14: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  notes_array = np.array([read_midi(path+i) for i in files])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#converting 2D array into 1D array\n",
        "notes_ = [element for note_ in notes_array for element in note_]\n",
        "\n",
        "#No. of unique notes\n",
        "unique_notes = list(set(notes_))\n",
        "print(len(unique_notes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nskE1jxStJIH",
        "outputId": "c3da45d4-67a4-4b55-c72e-769f9e156084"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "336\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#computing frequency of each note\n",
        "freq = dict(Counter(notes_))\n",
        "\n",
        "#library for visualiation\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#consider only the frequencies\n",
        "no=[count for _,count in freq.items()]\n",
        "\n",
        "#set the figure size\n",
        "plt.figure(figsize=(5,5))\n",
        "\n",
        "#plot\n",
        "plt.hist(no)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        },
        "id": "QlAcm4FMtJKi",
        "outputId": "05b7497f-5b38-449d-db39-711357087096"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([238.,  34.,  22.,   9.,   8.,   9.,   6.,   5.,   3.,   2.]),\n",
              " array([1.0000e+00, 1.5550e+02, 3.1000e+02, 4.6450e+02, 6.1900e+02,\n",
              "        7.7350e+02, 9.2800e+02, 1.0825e+03, 1.2370e+03, 1.3915e+03,\n",
              "        1.5460e+03]),\n",
              " <BarContainer object of 10 artists>)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "image/png": {
              "width": 456,
              "height": 428
            }
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Task 2: Data Preprocessing for Deep Learning**\n",
        "\n",
        "Here, the extracted notes are preprocessed to create input and output sequences for the LSTM model. Then, the data is split into training and validation sets."
      ],
      "metadata": {
        "id": "gtQTAKgA39_w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "frequent_notes = [note_ for note_, count in freq.items() if count>=50]\n",
        "print(len(frequent_notes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "in5AYc-Ht9RU",
        "outputId": "162ae4d1-ac9e-4d3b-b0f3-1e92b2137f91"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "159\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_music=[]\n",
        "\n",
        "for notes in notes_array:\n",
        "    temp=[]\n",
        "    for note_ in notes:\n",
        "        if note_ in frequent_notes:\n",
        "            temp.append(note_)\n",
        "    new_music.append(temp)\n",
        "\n",
        "new_music = np.array(new_music)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMCSlgGdtJNC",
        "outputId": "5c1377a1-7115-4489-9712-0755d06908af"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-2fa7923ce1b3>:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  new_music = np.array(new_music)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "no_of_timesteps = 32\n",
        "x = []\n",
        "y = []\n",
        "\n",
        "for note_ in new_music:\n",
        "    for i in range(0, len(note_) - no_of_timesteps, 1):\n",
        "\n",
        "        #preparing input and output sequences\n",
        "        input_ = note_[i:i + no_of_timesteps]\n",
        "        output = note_[i + no_of_timesteps]\n",
        "\n",
        "        x.append(input_)\n",
        "        y.append(output)\n",
        "\n",
        "x=np.array(x)\n",
        "y=np.array(y)"
      ],
      "metadata": {
        "id": "Vd2PGEnOtJPT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_x = list(set(x.ravel()))\n",
        "x_note_to_int = dict((note_, number) for number, note_ in enumerate(unique_x))"
      ],
      "metadata": {
        "id": "a2ZQ2Ox6uBcs"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#preparing input sequences\n",
        "x_seq=[]\n",
        "for i in x:\n",
        "    temp=[]\n",
        "    for j in i:\n",
        "        #assigning unique integer to every note\n",
        "        temp.append(x_note_to_int[j])\n",
        "    x_seq.append(temp)\n",
        "\n",
        "x_seq = np.array(x_seq)\n",
        "\n"
      ],
      "metadata": {
        "id": "7-3EQvlUtJSL"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#preparing output sequences\n",
        "unique_y = list(set(y))\n",
        "y_note_to_int = dict((note_, number) for number, note_ in enumerate(unique_y))\n",
        "y_seq=np.array([y_note_to_int[i] for i in y])"
      ],
      "metadata": {
        "id": "ObXYWjYitJU1"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_tr, x_val, y_tr, y_val = train_test_split(x_seq,y_seq,test_size=0.2,random_state=0)"
      ],
      "metadata": {
        "id": "EPunSYIAtJXk"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Task 3: Define the LSTM Model**\n",
        "\n",
        "The architecture of the LSTM-based deep learning model is defined here. It includes embedding, convolution, pooling, and dense layers for classification."
      ],
      "metadata": {
        "id": "7NiNaTDj4QgG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lstm():\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(128,return_sequences=True))\n",
        "  model.add(LSTM(128))\n",
        "  model.add(Dense(256))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dense(n_vocab))\n",
        "  model.add(Activation('softmax'))\n",
        "  model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
        "  return model"
      ],
      "metadata": {
        "id": "kIeqozRatJaK"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Task 4: Create the Deep Learning Model**\n",
        "\n",
        "In this section, the LSTM model is created and compiled."
      ],
      "metadata": {
        "id": "36_CKU_y47By"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "K.clear_session()\n",
        "model = Sequential()\n",
        "\n",
        "#embedding layer\n",
        "model.add(Embedding(len(unique_x), 100, input_length=32,trainable=True))\n",
        "\n",
        "model.add(Conv1D(64,3, padding='causal',activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(MaxPool1D(2))\n",
        "\n",
        "model.add(Conv1D(128,3,activation='relu',dilation_rate=2,padding='causal'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(MaxPool1D(2))\n",
        "\n",
        "model.add(Conv1D(256,3,activation='relu',dilation_rate=4,padding='causal'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(MaxPool1D(2))\n",
        "\n",
        "#model.add(Conv1D(256,5,activation='relu'))\n",
        "model.add(GlobalMaxPool1D())\n",
        "\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(len(unique_y), activation='softmax'))\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgFP24zdtJcU",
        "outputId": "507c9ab9-4b4e-4338-af9c-be23a69e9a36"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 32, 100)           15900     \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 32, 64)            19264     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 32, 64)            0         \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 16, 64)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 16, 128)           24704     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 16, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 8, 128)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 8, 256)            98560     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 8, 256)            0         \n",
            "                                                                 \n",
            " max_pooling1d_2 (MaxPooling  (None, 4, 256)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " global_max_pooling1d (Globa  (None, 256)              0         \n",
            " lMaxPooling1D)                                                  \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               65792     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 159)               40863     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 265,083\n",
            "Trainable params: 265,083\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Task 5: Train the Model**\n",
        "\n",
        "The model is trained using the preprocessed data, and the best model is saved."
      ],
      "metadata": {
        "id": "BU09qsW15XM0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mc=ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only=True,verbose=1)"
      ],
      "metadata": {
        "id": "x5dQCIQvtJfB"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(np.array(x_tr),np.array(y_tr),batch_size=128,epochs=50, validation_data=(np.array(x_val),np.array(y_val)),verbose=1, callbacks=[mc])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQpGox3ctJhc",
        "outputId": "e2dbc874-2519-4302-c516-f66fd6400041"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "358/359 [============================>.] - ETA: 0s - loss: 4.3848\n",
            "Epoch 1: val_loss improved from inf to 4.16970, saving model to best_model.h5\n",
            "359/359 [==============================] - 37s 98ms/step - loss: 4.3847 - val_loss: 4.1697\n",
            "Epoch 2/50\n",
            "358/359 [============================>.] - ETA: 0s - loss: 3.8915\n",
            "Epoch 2: val_loss improved from 4.16970 to 3.94095, saving model to best_model.h5\n",
            "359/359 [==============================] - 36s 100ms/step - loss: 3.8915 - val_loss: 3.9410\n",
            "Epoch 3/50\n",
            "358/359 [============================>.] - ETA: 0s - loss: 3.7223\n",
            "Epoch 3: val_loss improved from 3.94095 to 3.83041, saving model to best_model.h5\n",
            "359/359 [==============================] - 30s 84ms/step - loss: 3.7222 - val_loss: 3.8304\n",
            "Epoch 4/50\n",
            "358/359 [============================>.] - ETA: 0s - loss: 3.6105\n",
            "Epoch 4: val_loss improved from 3.83041 to 3.74420, saving model to best_model.h5\n",
            "359/359 [==============================] - 31s 85ms/step - loss: 3.6105 - val_loss: 3.7442\n",
            "Epoch 5/50\n",
            "358/359 [============================>.] - ETA: 0s - loss: 3.5203\n",
            "Epoch 5: val_loss improved from 3.74420 to 3.66988, saving model to best_model.h5\n",
            "359/359 [==============================] - 31s 87ms/step - loss: 3.5203 - val_loss: 3.6699\n",
            "Epoch 6/50\n",
            "358/359 [============================>.] - ETA: 0s - loss: 3.4359\n",
            "Epoch 6: val_loss improved from 3.66988 to 3.61972, saving model to best_model.h5\n",
            "359/359 [==============================] - 30s 84ms/step - loss: 3.4358 - val_loss: 3.6197\n",
            "Epoch 7/50\n",
            "358/359 [============================>.] - ETA: 0s - loss: 3.3708\n",
            "Epoch 7: val_loss improved from 3.61972 to 3.58972, saving model to best_model.h5\n",
            "359/359 [==============================] - 31s 87ms/step - loss: 3.3708 - val_loss: 3.5897\n",
            "Epoch 8/50\n",
            "358/359 [============================>.] - ETA: 0s - loss: 3.3073\n",
            "Epoch 8: val_loss improved from 3.58972 to 3.53652, saving model to best_model.h5\n",
            "359/359 [==============================] - 31s 87ms/step - loss: 3.3071 - val_loss: 3.5365\n",
            "Epoch 9/50\n",
            "358/359 [============================>.] - ETA: 0s - loss: 3.2552\n",
            "Epoch 9: val_loss improved from 3.53652 to 3.48709, saving model to best_model.h5\n",
            "359/359 [==============================] - 30s 84ms/step - loss: 3.2555 - val_loss: 3.4871\n",
            "Epoch 10/50\n",
            "358/359 [============================>.] - ETA: 0s - loss: 3.2106\n",
            "Epoch 10: val_loss improved from 3.48709 to 3.45416, saving model to best_model.h5\n",
            "359/359 [==============================] - 31s 87ms/step - loss: 3.2107 - val_loss: 3.4542\n",
            "Epoch 11/50\n",
            "358/359 [============================>.] - ETA: 0s - loss: 3.1696\n",
            "Epoch 11: val_loss improved from 3.45416 to 3.43265, saving model to best_model.h5\n",
            "359/359 [==============================] - 30s 84ms/step - loss: 3.1696 - val_loss: 3.4326\n",
            "Epoch 12/50\n",
            "358/359 [============================>.] - ETA: 0s - loss: 3.1285\n",
            "Epoch 12: val_loss improved from 3.43265 to 3.41189, saving model to best_model.h5\n",
            "359/359 [==============================] - 31s 87ms/step - loss: 3.1285 - val_loss: 3.4119\n",
            "Epoch 13/50\n",
            "358/359 [============================>.] - ETA: 0s - loss: 3.0976\n",
            "Epoch 13: val_loss improved from 3.41189 to 3.38201, saving model to best_model.h5\n",
            "359/359 [==============================] - 30s 84ms/step - loss: 3.0977 - val_loss: 3.3820\n",
            "Epoch 14/50\n",
            "358/359 [============================>.] - ETA: 0s - loss: 3.0596\n",
            "Epoch 14: val_loss improved from 3.38201 to 3.36627, saving model to best_model.h5\n",
            "359/359 [==============================] - 30s 84ms/step - loss: 3.0595 - val_loss: 3.3663\n",
            "Epoch 15/50\n",
            "358/359 [============================>.] - ETA: 0s - loss: 3.0295\n",
            "Epoch 15: val_loss did not improve from 3.36627\n",
            "359/359 [==============================] - 31s 87ms/step - loss: 3.0297 - val_loss: 3.3707\n",
            "Epoch 16/50\n",
            "358/359 [============================>.] - ETA: 0s - loss: 2.9999\n",
            "Epoch 16: val_loss improved from 3.36627 to 3.32910, saving model to best_model.h5\n",
            "359/359 [==============================] - 31s 86ms/step - loss: 3.0000 - val_loss: 3.3291\n",
            "Epoch 17/50\n",
            "358/359 [============================>.] - ETA: 0s - loss: 2.9749\n",
            "Epoch 17: val_loss improved from 3.32910 to 3.32016, saving model to best_model.h5\n",
            "359/359 [==============================] - 31s 87ms/step - loss: 2.9748 - val_loss: 3.3202\n",
            "Epoch 18/50\n",
            "358/359 [============================>.] - ETA: 0s - loss: 2.9465\n",
            "Epoch 18: val_loss improved from 3.32016 to 3.31983, saving model to best_model.h5\n",
            "359/359 [==============================] - 30s 84ms/step - loss: 2.9465 - val_loss: 3.3198\n",
            "Epoch 19/50\n",
            "358/359 [============================>.] - ETA: 0s - loss: 2.9261\n",
            "Epoch 19: val_loss improved from 3.31983 to 3.31098, saving model to best_model.h5\n",
            "359/359 [==============================] - 30s 84ms/step - loss: 2.9259 - val_loss: 3.3110\n",
            "Epoch 20/50\n",
            "358/359 [============================>.] - ETA: 0s - loss: 2.9036\n",
            "Epoch 20: val_loss improved from 3.31098 to 3.30306, saving model to best_model.h5\n",
            "359/359 [==============================] - 31s 87ms/step - loss: 2.9034 - val_loss: 3.3031\n",
            "Epoch 21/50\n",
            "358/359 [============================>.] - ETA: 0s - loss: 2.8829\n",
            "Epoch 21: val_loss improved from 3.30306 to 3.26874, saving model to best_model.h5\n",
            "359/359 [==============================] - 30s 84ms/step - loss: 2.8832 - val_loss: 3.2687\n",
            "Epoch 22/50\n",
            "358/359 [============================>.] - ETA: 0s - loss: 2.8586\n",
            "Epoch 22: val_loss did not improve from 3.26874\n",
            "359/359 [==============================] - 30s 83ms/step - loss: 2.8585 - val_loss: 3.2799\n",
            "Epoch 23/50\n",
            "358/359 [============================>.] - ETA: 0s - loss: 2.8415\n",
            "Epoch 23: val_loss improved from 3.26874 to 3.25778, saving model to best_model.h5\n",
            "359/359 [==============================] - 31s 87ms/step - loss: 2.8415 - val_loss: 3.2578\n",
            "Epoch 24/50\n",
            "358/359 [============================>.] - ETA: 0s - loss: 2.8172\n",
            "Epoch 24: val_loss improved from 3.25778 to 3.25448, saving model to best_model.h5\n",
            "359/359 [==============================] - 30s 84ms/step - loss: 2.8170 - val_loss: 3.2545\n",
            "Epoch 25/50\n",
            "358/359 [============================>.] - ETA: 0s - loss: 2.8015\n",
            "Epoch 25: val_loss improved from 3.25448 to 3.25209, saving model to best_model.h5\n",
            "359/359 [==============================] - 31s 88ms/step - loss: 2.8015 - val_loss: 3.2521\n",
            "Epoch 26/50\n",
            "358/359 [============================>.] - ETA: 0s - loss: 2.7898\n",
            "Epoch 26: val_loss did not improve from 3.25209\n",
            "359/359 [==============================] - 30s 84ms/step - loss: 2.7897 - val_loss: 3.2551\n",
            "Epoch 27/50\n",
            "358/359 [============================>.] - ETA: 0s - loss: 2.7733\n",
            "Epoch 27: val_loss improved from 3.25209 to 3.23723, saving model to best_model.h5\n",
            "359/359 [==============================] - 30s 84ms/step - loss: 2.7736 - val_loss: 3.2372\n",
            "Epoch 28/50\n",
            "358/359 [============================>.] - ETA: 0s - loss: 2.7564\n",
            "Epoch 28: val_loss improved from 3.23723 to 3.22790, saving model to best_model.h5\n",
            "359/359 [==============================] - 31s 87ms/step - loss: 2.7564 - val_loss: 3.2279\n",
            "Epoch 29/50\n",
            "358/359 [============================>.] - ETA: 0s - loss: 2.7425\n",
            "Epoch 29: val_loss improved from 3.22790 to 3.22360, saving model to best_model.h5\n",
            "359/359 [==============================] - 30s 84ms/step - loss: 2.7424 - val_loss: 3.2236\n",
            "Epoch 30/50\n",
            "358/359 [============================>.] - ETA: 0s - loss: 2.7229\n",
            "Epoch 30: val_loss did not improve from 3.22360\n",
            "359/359 [==============================] - 30s 83ms/step - loss: 2.7229 - val_loss: 3.2269\n",
            "Epoch 31/50\n",
            "358/359 [============================>.] - ETA: 0s - loss: 2.7133\n",
            "Epoch 31: val_loss improved from 3.22360 to 3.21949, saving model to best_model.h5\n",
            "359/359 [==============================] - 31s 87ms/step - loss: 2.7133 - val_loss: 3.2195\n",
            "Epoch 32/50\n",
            "358/359 [============================>.] - ETA: 0s - loss: 2.7100\n",
            "Epoch 32: val_loss improved from 3.21949 to 3.21773, saving model to best_model.h5\n",
            "359/359 [==============================] - 30s 83ms/step - loss: 2.7102 - val_loss: 3.2177\n",
            "Epoch 33/50\n",
            "358/359 [============================>.] - ETA: 0s - loss: 2.6922\n",
            "Epoch 33: val_loss improved from 3.21773 to 3.20656, saving model to best_model.h5\n",
            "359/359 [==============================] - 31s 88ms/step - loss: 2.6920 - val_loss: 3.2066\n",
            "Epoch 34/50\n",
            "358/359 [============================>.] - ETA: 0s - loss: 2.6821\n",
            "Epoch 34: val_loss did not improve from 3.20656\n",
            "359/359 [==============================] - 30s 84ms/step - loss: 2.6820 - val_loss: 3.2105\n",
            "Epoch 35/50\n",
            "358/359 [============================>.] - ETA: 0s - loss: 2.6656\n",
            "Epoch 35: val_loss improved from 3.20656 to 3.19305, saving model to best_model.h5\n",
            "359/359 [==============================] - 30s 84ms/step - loss: 2.6656 - val_loss: 3.1931\n",
            "Epoch 36/50\n",
            "358/359 [============================>.] - ETA: 0s - loss: 2.6588\n",
            "Epoch 36: val_loss improved from 3.19305 to 3.19018, saving model to best_model.h5\n",
            "359/359 [==============================] - 31s 87ms/step - loss: 2.6591 - val_loss: 3.1902\n",
            "Epoch 37/50\n",
            "358/359 [============================>.] - ETA: 0s - loss: 2.6539\n",
            "Epoch 37: val_loss did not improve from 3.19018\n",
            "359/359 [==============================] - 30s 84ms/step - loss: 2.6538 - val_loss: 3.1989\n",
            "Epoch 38/50\n",
            "358/359 [============================>.] - ETA: 0s - loss: 2.6390\n",
            "Epoch 38: val_loss did not improve from 3.19018\n",
            "359/359 [==============================] - 30s 85ms/step - loss: 2.6391 - val_loss: 3.2005\n",
            "Epoch 39/50\n",
            "358/359 [============================>.] - ETA: 0s - loss: 2.6282\n",
            "Epoch 39: val_loss did not improve from 3.19018\n",
            "359/359 [==============================] - 31s 87ms/step - loss: 2.6281 - val_loss: 3.1913\n",
            "Epoch 40/50\n",
            "358/359 [============================>.] - ETA: 0s - loss: 2.6221\n",
            "Epoch 40: val_loss did not improve from 3.19018\n",
            "359/359 [==============================] - 30s 84ms/step - loss: 2.6221 - val_loss: 3.2010\n",
            "Epoch 41/50\n",
            "358/359 [============================>.] - ETA: 0s - loss: 2.6169\n",
            "Epoch 41: val_loss improved from 3.19018 to 3.18948, saving model to best_model.h5\n",
            "359/359 [==============================] - 31s 87ms/step - loss: 2.6170 - val_loss: 3.1895\n",
            "Epoch 42/50\n",
            "358/359 [============================>.] - ETA: 0s - loss: 2.5988\n",
            "Epoch 42: val_loss improved from 3.18948 to 3.18170, saving model to best_model.h5\n",
            "359/359 [==============================] - 30s 84ms/step - loss: 2.5988 - val_loss: 3.1817\n",
            "Epoch 43/50\n",
            "358/359 [============================>.] - ETA: 0s - loss: 2.5898\n",
            "Epoch 43: val_loss did not improve from 3.18170\n",
            "359/359 [==============================] - 30s 84ms/step - loss: 2.5898 - val_loss: 3.1822\n",
            "Epoch 44/50\n",
            "358/359 [============================>.] - ETA: 0s - loss: 2.5896\n",
            "Epoch 44: val_loss improved from 3.18170 to 3.17602, saving model to best_model.h5\n",
            "359/359 [==============================] - 31s 87ms/step - loss: 2.5895 - val_loss: 3.1760\n",
            "Epoch 45/50\n",
            "358/359 [============================>.] - ETA: 0s - loss: 2.5803\n",
            "Epoch 45: val_loss did not improve from 3.17602\n",
            "359/359 [==============================] - 30s 84ms/step - loss: 2.5802 - val_loss: 3.1763\n",
            "Epoch 46/50\n",
            "358/359 [============================>.] - ETA: 0s - loss: 2.5784\n",
            "Epoch 46: val_loss improved from 3.17602 to 3.17037, saving model to best_model.h5\n",
            "359/359 [==============================] - 30s 84ms/step - loss: 2.5784 - val_loss: 3.1704\n",
            "Epoch 47/50\n",
            "358/359 [============================>.] - ETA: 0s - loss: 2.5639\n",
            "Epoch 47: val_loss improved from 3.17037 to 3.16611, saving model to best_model.h5\n",
            "359/359 [==============================] - 31s 87ms/step - loss: 2.5642 - val_loss: 3.1661\n",
            "Epoch 48/50\n",
            "358/359 [============================>.] - ETA: 0s - loss: 2.5542\n",
            "Epoch 48: val_loss did not improve from 3.16611\n",
            "359/359 [==============================] - 30s 83ms/step - loss: 2.5541 - val_loss: 3.1730\n",
            "Epoch 49/50\n",
            "358/359 [============================>.] - ETA: 0s - loss: 2.5498\n",
            "Epoch 49: val_loss improved from 3.16611 to 3.16412, saving model to best_model.h5\n",
            "359/359 [==============================] - 32s 88ms/step - loss: 2.5498 - val_loss: 3.1641\n",
            "Epoch 50/50\n",
            "358/359 [============================>.] - ETA: 0s - loss: 2.5383\n",
            "Epoch 50: val_loss did not improve from 3.16412\n",
            "359/359 [==============================] - 30s 84ms/step - loss: 2.5386 - val_loss: 3.1803\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Task 6: Load the Best Model and Generate New Music**\n",
        "\n",
        "The best model is loaded, and new music sequences are generated using random starting notes. The generated sequences are then converted back to music notes and saved as a MIDI file for playback or analysis."
      ],
      "metadata": {
        "id": "oUW357Jk501U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#loading best model\n",
        "from keras.models import load_model\n",
        "model = load_model('best_model.h5')"
      ],
      "metadata": {
        "id": "AYC7a31CtJkH"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "ind = np.random.randint(0,len(x_val)-1)\n",
        "\n",
        "random_music = x_val[ind]\n",
        "\n",
        "predictions=[]\n",
        "for i in range(10):\n",
        "\n",
        "    random_music = random_music.reshape(1,no_of_timesteps)\n",
        "\n",
        "    prob  = model.predict(random_music)[0]\n",
        "    y_pred= np.argmax(prob,axis=0)\n",
        "    predictions.append(y_pred)\n",
        "\n",
        "    random_music = np.insert(random_music[0],len(random_music[0]),y_pred)\n",
        "    random_music = random_music[1:]\n",
        "\n",
        "print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TCBS2-_uds_",
        "outputId": "86510986-4b87-44bb-92fd-10ec91f71c9b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "[97, 97, 97, 101, 97, 97, 97, 97, 97, 97]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_int_to_note = dict((number, note_) for number, note_ in enumerate(unique_x))\n",
        "predicted_notes = [x_int_to_note[i] for i in predictions]"
      ],
      "metadata": {
        "id": "Iv0dDGXBudvl"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_midi(prediction_output):\n",
        "\n",
        "    offset = 0\n",
        "    output_notes = []\n",
        "\n",
        "    # create note and chord objects based on the values generated by the model\n",
        "    for pattern in prediction_output:\n",
        "\n",
        "        # pattern is a chord\n",
        "        if ('.' in pattern) or pattern.isdigit():\n",
        "            notes_in_chord = pattern.split('.')\n",
        "            notes = []\n",
        "            for current_note in notes_in_chord:\n",
        "\n",
        "                cn=int(current_note)\n",
        "                new_note = note.Note(cn)\n",
        "                new_note.storedInstrument = instrument.Piano()\n",
        "                notes.append(new_note)\n",
        "\n",
        "            new_chord = chord.Chord(notes)\n",
        "            new_chord.offset = offset\n",
        "            output_notes.append(new_chord)\n",
        "\n",
        "        # pattern is a note\n",
        "        else:\n",
        "\n",
        "            new_note = note.Note(pattern)\n",
        "            new_note.offset = offset\n",
        "            new_note.storedInstrument = instrument.Piano()\n",
        "            output_notes.append(new_note)\n",
        "\n",
        "        # increase offset each iteration so that notes do not stack\n",
        "        offset += 1\n",
        "    midi_stream = stream.Stream(output_notes)\n",
        "    midi_stream.write('midi', fp='output.mid')\n"
      ],
      "metadata": {
        "id": "41ZIsoC8uiul"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "convert_to_midi(predicted_notes)"
      ],
      "metadata": {
        "id": "0n9_gmvE2s9k"
      },
      "execution_count": 26,
      "outputs": []
    }
  ]
}